{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:35.404451Z","iopub.execute_input":"2025-11-16T06:04:35.405295Z","iopub.status.idle":"2025-11-16T06:04:35.782370Z","shell.execute_reply.started":"2025-11-16T06:04:35.405259Z","shell.execute_reply":"2025-11-16T06:04:35.781257Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"\"\"\"\n    IMAGE FORGERY ASSISTANT - INTERACTIVE DEMO\n    +++++++++++++++++++++++++++++++++++++++++++\n\n    FEATURES:\n    1. Multi-agent system with specialized tools\n    2. Hybrid architecture\n    3. Interactive chat interface\n    4. Real-tiem responses\n\n    Developer: Praful Pawar\n    \n\"\"\"\n","metadata":{}},{"cell_type":"code","source":"# instal dependecies\n!pip install -q google-generativeai ipywidgets \nprint(\"Dependecies installed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:35.784062Z","iopub.execute_input":"2025-11-16T06:04:35.784695Z","iopub.status.idle":"2025-11-16T06:04:43.345627Z","shell.execute_reply.started":"2025-11-16T06:04:35.784657Z","shell.execute_reply":"2025-11-16T06:04:43.344299Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mDependecies installed!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#import required libraries\n\nimport os\nimport time\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\n#Google Generative Ai\nfrom google import genai\nfrom google.genai import types\n\n#Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\n\n#Widgets for interactive chat\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML\n\nprint(\"Imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:43.346912Z","iopub.execute_input":"2025-11-16T06:04:43.347227Z","iopub.status.idle":"2025-11-16T06:04:48.529168Z","shell.execute_reply.started":"2025-11-16T06:04:43.347198Z","shell.execute_reply":"2025-11-16T06:04:48.528264Z"}},"outputs":[{"name":"stdout","text":"Imports successful!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\"Agent Configuration\"\n#Get API key from kaggle secrets\n#important:add your google_api_key in kaggle secrets first\n#go to : Add-ons -> secrets ->add secret\n#Label: Google_API_Key\n#Value:[your API key]\n\ntry:\n    user_secrets = UserSecretsClient()\n    GOOGLE_API_KEY = user_secrets.get_secret(\"Kaggle_Api_key\")\n    print(\"API Key loaded from secrets!\")\nexcept:\n      print(\"Warning:Could not load API key from secrets\")\n      print(\"please add google api key to kaggle Secrets\")\n\n      GOOGLE_API_KEY= None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:48.530783Z","iopub.execute_input":"2025-11-16T06:04:48.531452Z","iopub.status.idle":"2025-11-16T06:04:48.691933Z","shell.execute_reply.started":"2025-11-16T06:04:48.531427Z","shell.execute_reply":"2025-11-16T06:04:48.691003Z"}},"outputs":[{"name":"stdout","text":"API Key loaded from secrets!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Agent Configuration\nAGENT_CONFIG ={\n    \"user_name\" : \"Praful\",\n    \"competition\": \"Record.ai/LUC Scientific Image Forgery Detection\",\n    \"current_model\": \"EfficientNet-B4 UNet++\",\n    \"current_score\": 0.303, \n    \"target_score\" :0.350,\n    \"version\": \"1.0.0\"\n}\n\n#Display configuration\nprint(\"\\n\" + \"=\"*70)\nprint(\"Agent Configuration\")\nprint(\"=\"*70)\nfor key, value in AGENT_CONFIG.items():\n    print(f\". {key}:{value}\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:48.693200Z","iopub.execute_input":"2025-11-16T06:04:48.693647Z","iopub.status.idle":"2025-11-16T06:04:48.700450Z","shell.execute_reply.started":"2025-11-16T06:04:48.693617Z","shell.execute_reply":"2025-11-16T06:04:48.699587Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nAgent Configuration\n======================================================================\n. user_name:Praful\n. competition:Record.ai/LUC Scientific Image Forgery Detection\n. current_model:EfficientNet-B4 UNet++\n. current_score:0.303\n. target_score:0.35\n. version:1.0.0\n======================================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\"\"\"\nLLM Interface - Optimized for Kaggle\nUses Gemini API (cloud-based, no local server needed)\n\"\"\"\n\nimport time\nimport google.generativeai as genai\nfrom google.generativeai import types\nfrom kaggle_secrets import UserSecretsClient\n\n\nclass KaggleLLM:\n    \"\"\"\n    Simplified LLM for Kaggle environment\n    Uses Google Gemini API\n    \"\"\"\n    \n    def __init__(self, api_key: str):\n        if not api_key:\n            raise ValueError(\"API key is required\")\n\n        # Configure Gemini\n        genai.configure(api_key=api_key)\n        \n        self.client = genai\n        self.model = \"gemini-2.0-flash-exp\"\n        self.call_count = 0\n        self.total_time = 0\n        \n        print(f\"✅ LLM initialized with model: {self.model}\")\n    \n    def call(\n        self, \n        prompt: str, \n        max_tokens: int = 1000, \n        temperature: float = 0.3,\n        system_prompt: str = None\n    ) -> str:\n\n        \"\"\"\n        Call Gemini API\n        \"\"\"\n\n        try:\n            # Combine system prompt if provided\n            full_prompt = prompt\n            if system_prompt:\n                full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n            \n            # Track timing\n            start_time = time.time()\n            \n            # Call API\n            response = self.client.GenerativeModel(self.model).generate_content(\n                full_prompt,\n                generation_config=types.GenerationConfig(\n                    max_output_tokens=max_tokens,\n                    temperature=temperature\n                )\n            )\n            \n            # Update stats\n            elapsed = time.time() - start_time\n            self.call_count += 1\n            self.total_time += elapsed\n            \n            return response.text\n            \n        except Exception as e:\n            return f\"❌ Error calling LLM: {str(e)}\"\n    \n    def get_stats(self) -> dict:\n        \"\"\"Get LLM usage statistics\"\"\"\n        \n        avg_time = self.total_time / self.call_count if self.call_count > 0 else 0\n        \n        return {\n            \"total_calls\": self.call_count,\n            \"total_time\": round(self.total_time, 2),\n            \"avg_time\": round(avg_time, 2)\n        }\n\n\n# ----------------------------------------------------------\n# Load API Key from Kaggle Secrets\n# ----------------------------------------------------------\n\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"Kaggle_Api_key\")\n\n\n# Initialize global LLM instance\n\nif GOOGLE_API_KEY:\n    llm = KaggleLLM(GOOGLE_API_KEY)\n    print(\"✅ LLM ready to use!\")\nelse:\n    llm = None\n    print(\"⚠️ LLM not initialized - API key missing\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T06:04:48.701640Z","iopub.execute_input":"2025-11-16T06:04:48.701975Z","iopub.status.idle":"2025-11-16T06:04:52.929829Z","shell.execute_reply.started":"2025-11-16T06:04:48.701944Z","shell.execute_reply":"2025-11-16T06:04:52.928596Z"}},"outputs":[{"name":"stdout","text":"✅ LLM initialized with model: gemini-2.0-flash-exp\n✅ LLM ready to use!\n","output_type":"stream"}],"execution_count":6}]}